{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "import random\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rraj/PythonFunctions/DCNet'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/Users/rraj/PythonFunctions/DCNet/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelData:\n",
    "    def read_data(self, data_identifier: str, data_type: str):\n",
    "        file_path = self.check_identifier(data_identifier)\n",
    "        \n",
    "        f = shelve.open(file_path[:-3], 'r')\n",
    "        if data_type == 'train':\n",
    "            data = f['train_dict']\n",
    "        elif data_type == 'test':\n",
    "            data = f['train_dict']\n",
    "        else:\n",
    "            raise Exception(\"invalid data type requested\")\n",
    "        f.close()\n",
    "        return data\n",
    "    \n",
    "    def check_identifier(self, data_identifier: str):\n",
    "        file_path = data_identifier\n",
    "        if 'Data' not in data_identifier:\n",
    "            file_path = os.path.join(os.getcwd(), 'Data', 'Data-'+data_identifier+'.db')\n",
    "        \n",
    "        if not os.path.isfile(file_path):\n",
    "            raise FileNotFoundError(f\"{file_path} not found\")\n",
    "        else:\n",
    "            return file_path\n",
    "        \n",
    "        \n",
    "    def labels_to_index_dict(self, data: dict):\n",
    "        return {label : indx for indx, label in enumerate(data.keys())}\n",
    "    \n",
    "    def index_to_labels_dict(self, labels_to_index_dict: dict):\n",
    "        return {indx : label for label, indx in labels_to_index_dict.items()}\n",
    "    \n",
    "    def get_nclasses(self, data: dict):\n",
    "        return len(data.keys())\n",
    "    \n",
    "    def get_sample_sizes(self, data: dict, index_to_label_dict: dict):\n",
    "        sample_sizes = []\n",
    "        for indx in range(len(data)):\n",
    "            label = index_to_label_dict.get(indx, None)\n",
    "            sample_sizes.append(data[label].shape[1])\n",
    "        return sample_sizes\n",
    "\n",
    "    def get_max_batch_size(self, sample_sizes: list):\n",
    "        return min(sample_sizes)*len(sample_sizes)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainData(ModelData, Dataset):\n",
    "    def __init__(self, data_identifier: str):\n",
    "        self.data = self.read_data(data_identifier, 'train')\n",
    "        self.nclasses = self.get_nclasses(self.data)\n",
    "        self.labels_to_index = self.labels_to_index_dict(self.data)\n",
    "        self.index_to_labels = self.index_to_labels_dict(self.labels_to_index)\n",
    "        self.sample_sizes = self.get_sample_sizes(self.data, self.index_to_labels)\n",
    "        self.max_batch_size = self.get_max_batch_size(self.sample_sizes)\n",
    "\n",
    "    def __len__(self):\n",
    "        total_samples = 0\n",
    "        for value in self.data.values():\n",
    "            total_samples += value.shape[1]\n",
    "        return total_samples\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if isinstance(index, tuple) and len(index) == 2:\n",
    "            k = self.index_to_labels.get(index[0], None)\n",
    "            return torch.unsqueeze(torch.from_numpy(self.data[k][:, index[1]]), 0)\n",
    "        else:\n",
    "            raise IndexError(f\"{index} not supported\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestData(ModelData, Dataset):\n",
    "    def __init__(self, data_identifier: str):\n",
    "        self.data = self.read_data(data_identifier, 'test')\n",
    "        self.labels_to_index = self.labels_to_index_dict(self.data)\n",
    "        self.nclasses = self.get_nclasses(self.data)\n",
    "        self.index_to_labels = self.index_to_labels_dict(self.labels_to_index)\n",
    "        self.sample_sizes = self.get_sample_sizes(self.data, self.index_to_labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        total_samples = 0\n",
    "        for value in self.data.values():\n",
    "            total_samples += value.shape[1]\n",
    "        return total_samples\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if isinstance(index, tuple) and len(index) == 2:\n",
    "            k = self.index_to_labels.get(index[0], None)\n",
    "            return torch.unsqueeze(torch.from_numpy(self.data[k][:, index[1]]), 0)\n",
    "        else:\n",
    "            raise IndexError(f\"{index} not supported\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainLoader:\n",
    "    def __init__(self, data_source, batch_size: int = 0, n_iter: int = 1, shuffle: bool = False):\n",
    "        self.data_source = data_source\n",
    "        self.n_iter = n_iter\n",
    "        self.shuffle = shuffle\n",
    "        self.returned_index = 0\n",
    "        self.adjusted_batch_size = self.adjust_batch_size(batch_size)\n",
    "        self.nsamples = self.get_nsamples()\n",
    "        self.class_indices_r = self.get_randomized_class_indices()\n",
    "        self.sample_indices_r = self.get_randomized_sample_indices()\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.n_iter > 0 and self.returned_index < self.adjusted_batch_size:\n",
    "            c_indx, s_indx = divmod(self.returned_index, self.nsamples)\n",
    "            self.returned_index += 1\n",
    "            self.update_batch()\n",
    "            if self.shuffle:\n",
    "                indx = self.class_indices_r[c_indx], random.randrange(self.data_source.sample_sizes[c_indx])\n",
    "                return self.data_source[indx]\n",
    "            else:\n",
    "                indx = self.class_indices_r[c_indx], (self.sample_indices_r[c_indx] + s_indx)\n",
    "                return self.data_source[indx]\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "    def update_batch(self):\n",
    "        if self.returned_index == self.adjusted_batch_size:\n",
    "            self.n_iter -= 1\n",
    "            random.shuffle(self.class_indices_r)\n",
    "            self.sample_indices_r = self.get_randomized_sample_indices()\n",
    "            self.returned_index = 0\n",
    "        \n",
    "    def adjust_batch_size(self, batch_size: int):\n",
    "        adjusted_batch_size = min(max(batch_size//self.data_source.nclasses, 1) * self.data_source.nclasses, self.data_source.max_batch_size)\n",
    "        if adjusted_batch_size != batch_size:\n",
    "            warnings.warn(f\"batch size adjusted to {adjusted_batch_size}\")\n",
    "        return adjusted_batch_size\n",
    "\n",
    "    def get_nsamples(self):\n",
    "        return (self.adjusted_batch_size//self.data_source.nclasses)\n",
    "    \n",
    "    def get_randomized_class_indices(self):\n",
    "        class_indices_r = [*range(self.data_source.nclasses)]\n",
    "        random.shuffle(class_indices_r)\n",
    "        return class_indices_r\n",
    "    \n",
    "    def get_randomized_sample_indices(self):\n",
    "        sample_indices_r = []\n",
    "        for indx in self.class_indices_r:\n",
    "            random_start_limit = self.data_source.sample_sizes[indx] - self.nsamples\n",
    "            sample_indices_r.append(random.randint(0, random_start_limit))\n",
    "        return sample_indices_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestLoader:\n",
    "    def __init__(self, data_source):\n",
    "        self.data_source = data_source\n",
    "        self.returned_class_indx = 0\n",
    "        self.returned_sample_indx = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.returned_class_indx < self.data_source.nclasses and self.returned_sample_indx < self.data_source.sample_sizes[self.returned_class_indx]:\n",
    "            indx = self.returned_class_indx, self.returned_sample_indx\n",
    "            self.returned_sample_indx += 1\n",
    "            self.update_class()\n",
    "            return self.data_source[indx]\n",
    "        else:\n",
    "            raise StopIteration\n",
    "    \n",
    "    def update_class(self):\n",
    "        if self.returned_sample_indx == self.data_source.sample_sizes[self.returned_class_indx]:\n",
    "            self.returned_class_indx += 1\n",
    "            self.returned_sample_indx = 0\n",
    "\n",
    "    def get_index_to_class_dict(self):\n",
    "        return self.data_source.index_to_labels\n",
    "    \n",
    "    def get_class_to_index_dict(self):\n",
    "        return self.data_source.labels_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = TrainData('May04-2357')\n",
    "train_loader = TrainLoader(train_inputs, batch_size=128, n_iter=2)\n",
    "test_inputs = TestData('May04-2357')\n",
    "test_loader = TestLoader(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:This message should appear on the console\n",
      "INFO:So should this\n",
      "WARNING:And this, too\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)\n",
    "logging.debug('This message should appear on the console')\n",
    "logging.info('So should this')\n",
    "logging.warning('And this, too')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "tensor([13.9901,  2.8770,  0.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import normalize\n",
    "from torch.linalg import multi_dot\n",
    "\n",
    "def get_init_batch(train_inputs: TrainData):\n",
    "    batch_size = int(0.25*len(train_inputs))\n",
    "    train_loader = TrainLoader(train_inputs, batch_size=batch_size)\n",
    "    init_batch = torch.empty((batch_size))\n",
    "    for input in train_loader:\n",
    "        try:\n",
    "            init_batch = torch.vstack((init_batch, input))\n",
    "        except:\n",
    "            init_batch = input\n",
    "    return init_batch\n",
    "\n",
    "def get_ncomps(S: torch.Tensor):\n",
    "    assert S.dim() == 1\n",
    "    S_n = S**2/torch.sum(S**2)\n",
    "    n_comp = 0\n",
    "    sum_comp = 0\n",
    "    for comp in S_n:\n",
    "        sum_comp += comp\n",
    "        n_comp += 1\n",
    "        if sum_comp > 0.95:\n",
    "            break\n",
    "    return n_comp\n",
    "\n",
    "def randomizer_matrix(m: int, n: int):\n",
    "    assert m > n\n",
    "    temp = torch.rand(m, m)\n",
    "    U, _, _ = torch.pca_lowrank(temp)\n",
    "    return U[:, :n]\n",
    "\n",
    "def input_svd_matrices(init_batch: torch.Tensor):\n",
    "    _, S, V = torch.pca_lowrank(init_batch)\n",
    "    n_comps = get_ncomps(S)\n",
    "    return V[:, :n_comps], S[:n_comps], n_comps\n",
    "\n",
    "def initialize_network_connections(layer_dims: list, data_identifier: str):\n",
    "    train_inputs = TrainData(data_identifier)\n",
    "    init_batch = get_init_batch(train_inputs)\n",
    "    left_matrix, sigma, n = input_svd_matrices(init_batch)\n",
    "    sigma_r = sigma**(-1/len(layer_dims))\n",
    "    \n",
    "    for dim in layer_dims:\n",
    "        right_matrix = randomizer_matrix(layer_dims[dim], n)\n",
    "        w = multi_dot([left_matrix, torch.diag(sigma_r), right_matrix.T])\n",
    "        w_n = normalize(w, p=2.0, dim=1)\n",
    "        left_matrix = right_matrix\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class HashLayer(nn.Module):\n",
    "    def __init__(self, input_size: int, hash_length: int):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_size, hash_length, bias=False)\n",
    "        self.activation = nn.ReLU()\n",
    "        # initialize custom wights (maybe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        out = self.fc(x)\n",
    "        out = self.activation(out)\n",
    "        return self.hash_function(torch.sign(out))\n",
    "    \n",
    "    def hash_function(self, out: torch.Tensor):\n",
    "        assert out.dim() > 1\n",
    "        out_f, final_shape = self.flatten_tensor(out)\n",
    "        hash_values = torch.empty((out_f.shape[0], 1))\n",
    "        for indx, row in enumerate(out_f):\n",
    "            hash_values[indx, 0] = sum(v*2**i for i, v in enumerate(reversed(row)))\n",
    "        \n",
    "        return hash_values.reshape(final_shape)\n",
    "    \n",
    "    def flatten_tensor(self, t: torch.Tensor):\n",
    "        t_f = t\n",
    "        if t.dim() > 2:\n",
    "            t_f = torch.flatten(t, end_dim=1)\n",
    "        return t_f, t.shape[:-1]\n",
    "\n",
    "    \n",
    "class ParallelHash(nn.Module):\n",
    "    def __init__(self, n_heads: int, hash_layer: nn.Module):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        torch.empty(())\n",
    "    \n",
    "\n",
    "\n",
    "# implement to get input indices or make sure that at max bach size inputs are generated orederly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.]], grad_fn=<ReshapeAliasBackward0>)\n",
      "tensor([4., 4., 0., 5., 5.], grad_fn=<ReshapeAliasBackward0>)\n",
      "tensor([[4., 4., 0., 5., 5.],\n",
      "        [4., 4., 0., 5., 5.]], grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a1 = torch.tensor([[[1, 2, 3, 4]]], dtype=torch.float)\n",
    "a2 = torch.tensor([[1, 1, 1, 1],[5, 6, 7, 8], [0, 0, 0, 0], [6, 4, 5, 2], [7, 3, 9, 1]], dtype=torch.float)\n",
    "a3 = torch.vstack((a2, a2)).reshape(2, 5, 4)\n",
    "\n",
    "hash = HashLayer(4, 3)\n",
    "\n",
    "print(hash(a1))\n",
    "print(hash(a2))\n",
    "print(hash(a3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckCustom()\n"
     ]
    }
   ],
   "source": [
    "n_heads = 3\n",
    "parallel_hash = [HashLayer(4, 3) for _ in range(n_heads)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0]\n",
      "tensor([[1, 0, 0]])\n",
      "[1 1 0]\n",
      "tensor([[1, 1, 0]])\n",
      "tensor([[1, 0, 0],\n",
      "        [1, 1, 0]])\n",
      "tensor([[2, 1, 1],\n",
      "        [2, 2, 1]])\n",
      "torch.Size([2, 1])\n",
      "tensor([[4.],\n",
      "        [6.]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([[1, 0, 0], [1, 1, 0]])\n",
    "t = torch.tensor([])\n",
    "for row in x:\n",
    "    print(row)\n",
    "    t_xr = torch.unsqueeze(torch.from_numpy(row), 0)\n",
    "    print(t_xr)\n",
    "    try:\n",
    "        t = torch.vstack([t, t_xr])\n",
    "    except Exception:\n",
    "        t = t_xr\n",
    "\n",
    "print(t)\n",
    "print(2**t)\n",
    "vals = torch.empty((2, 1))\n",
    "print(vals.shape)\n",
    "for indx, row in enumerate(t):\n",
    "    vals[indx, 0] = sum(v*2**i for i, v in enumerate(reversed(row)))\n",
    "\n",
    "print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2   3\n"
     ]
    }
   ],
   "source": [
    "m, n = t.shape\n",
    "print(m, \" \", n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
